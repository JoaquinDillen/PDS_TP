{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4984dd1b",
   "metadata": {},
   "source": [
    "# Phonem Feature Extraction Detection \n",
    "\n",
    "This code have the purpose of perfomer phonem detection out of a voice recorder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hunga_bunga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c495bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f76e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import math\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import sin, cos, pi, linspace, arange, log10, absolute\n",
    "from numpy.random import randn\n",
    "from scipy.signal import lfilter, lfilter_zi, filtfilt, butter, freqz, welch\n",
    "from scipy.io.wavfile import read , write\n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ee698",
   "metadata": {},
   "source": [
    "# Load audio file and present their information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load one specific audio\n",
    "\n",
    "filename = 'A_lata_01.wav'\n",
    "directory = 'C:/Users/Dasil/1. Processamento Digital do Sinal/Project/word Detection/training/' + filename\n",
    "\n",
    "fs, audio1 = read(directory)\n",
    "f,t,S1 = spectrogram(audio1, fs, window='flattop', nperseg=fs//10, noverlap=fs//20, scaling='spectrum', mode='magnitude')\n",
    "\n",
    "#print information about the audio\n",
    "print('filename: ', filename)\n",
    "print('Data Length (s): ',t[-1])\n",
    "print('Sampling frequency (samples/s): ', fs)\n",
    "\n",
    "#Playing Audio (Reproduce Audio)\n",
    "ipd.Audio(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5428921",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92250801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cepstrum and Power Spectrum\n",
    "\n",
    "def real_cepstrum(x, n=None):\n",
    "# Compute the real cepstrum of a real sequence\n",
    "#    x : ndarray\n",
    "#        Real sequence to compute real cepstrum of.\n",
    "#    n : {None, int}, optional\n",
    "#        Length of the Fourier transform.\n",
    "#    Returns\n",
    "#    -------\n",
    "#    ceps: ndarray\n",
    "#        The real cepstrum.\n",
    "\n",
    "    spectrum = np.abs(np.fft.fft(x, n=n))**2\n",
    "    ceps = np.fft.ifft(np.log(spectrum))\n",
    "\n",
    "    return ceps, spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2509bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero Crossing Rate\n",
    "\n",
    "def ZCR(samples, frameSize, overlap):\n",
    "    wlen = len(samples)\n",
    "    step = frameSize - overlap\n",
    "    frameNum = math.ceil(wlen/step)\n",
    "    zcr = np.zeros((frameNum,1))\n",
    "    for i in range(frameNum):\n",
    "        curFrame = samples[np.arange(i*step,min(i*step+frameSize,wlen))]\n",
    "        #To avoid DC bias, usually we need to perform mean substraction on each frame\n",
    "        curFrame = curFrame - np.mean(curFrame) #Zero-Justified\n",
    "        zcr[i] = sum(curFrame[0:-1]*curFrame[1::]<=0)\n",
    "    return zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23033152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro ButterWord\n",
    "\n",
    "wn = 1500/(fs/2)\n",
    "b3,a3 = butter(4, wn)\n",
    "#Apply the filter\n",
    "audio1_filt = lfilter(b3,a3,audio1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41fa2b",
   "metadata": {},
   "source": [
    "# First Audio Segmentation\n",
    "\n",
    "Separate the word from the rest of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e239d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply first threshold\n",
    "results = [1 if item > 500 else 0 for item in audio1_filt]\n",
    "\n",
    "# Variables\n",
    "x1 = x2 = 0\n",
    "flag = False\n",
    "chunks = []\n",
    "coordinates = []\n",
    "zeros_list = []\n",
    "silence_len = 10000\n",
    "min_len = 10000\n",
    "\n",
    "plt.plot(results)\n",
    "for i, result in enumerate(results):\n",
    "    # First signal rise\n",
    "    if(flag == False and result == 1 and x1 == 0):\n",
    "        flag = True\n",
    "        x1 = i\n",
    "    # Check if fall is permanent\n",
    "    if(flag == True):\n",
    "        if(result == 0):\n",
    "            zeros_list.append(result)\n",
    "        else:\n",
    "            zeros_list = []\n",
    "    # Signal fall\n",
    "    if(flag == True and len(zeros_list) >= silence_len and x2 == 0):\n",
    "        flag = False\n",
    "        x2 = i - len(zeros_list)\n",
    "        # If data is valid, save it in list\n",
    "        if(not x2-x1 <= min_len):\n",
    "            chunks.append(results[x1:x2+1])\n",
    "            coordinates.append([x1, x2])\n",
    "            plt.plot([x1, x1], [0, 1], [x2, x2], [0, 1], marker='o')\n",
    "        # Reset to initial state\n",
    "        x1 = x2 = 0\n",
    "\n",
    "print(f'# of chunks detected: {len(chunks)}')\n",
    "\n",
    "pt1 = coordinates[0]\n",
    "try:\n",
    "    pt2 = coordinates[1]\n",
    "    div_ptn = ((pt2[0] - pt1[1]) / 2) + pt1[1]\n",
    "except:\n",
    "    div_ptn = ((pt1[1] + pt1[0]) / 2)\n",
    "    \n",
    "# Draw dividing line\n",
    "plt.plot([div_ptn, div_ptn], [0, 1], marker='o', color=\"black\")\n",
    "print(pt1[0], pt1[1])\n",
    "print(pt1[1] - pt1[0])\n",
    "\n",
    "#Make segmentation point integer\n",
    "div_ptn = round(div_ptn)\n",
    "\n",
    "# Fix-sized segmentation (breaks a signal into non-overlapping segments)\n",
    "signal = audio1 / (2**15)\n",
    "signal_len = len(signal)\n",
    "segment_size_t = 1 # segment size in seconds\n",
    "segment_size = segment_size_t * fs  # segment size in samples\n",
    "\n",
    "# Break signal into list of segments in a single-line Python code\n",
    "segment1 = audio1[:div_ptn]\n",
    "segment2 = audio1[div_ptn:]\n",
    "segments = [segment1, segment2]\n",
    "\n",
    "# Find out the number of Segments\n",
    "n = len(segments)\n",
    "\n",
    "# Acess the first chunk of the audio\n",
    "samples = segments[0]\n",
    "samples = np.array(samples)\n",
    "\n",
    "# Process each chunk\n",
    "# Save each segment in a seperate filename\n",
    "for iS, s in enumerate(segments):\n",
    "    write('Word Detection/PD_data/'+filename+'_{0:d}.wav'.format(segment_size_t * iS, segment_size_t * (iS + 1)), fs, (s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d76ac6",
   "metadata": {},
   "source": [
    "# Word Selection for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbba9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load one specific word\n",
    "\n",
    "filename = 'A_lata_01'\n",
    "directory = 'C:/Users/Dasil/1. Processamento Digital do Sinal/Project/word Detection/training/' + filename + '_1.wav'\n",
    "\n",
    "fs, word = read(directory)\n",
    "f,t,S1 = spectrogram(word, fs, window='flattop', nperseg=fs//10, noverlap=fs//20, scaling='spectrum', mode='magnitude')\n",
    "\n",
    "#print information about the word\n",
    "print('filename: ', filename)\n",
    "print('Data Length (s): ',t[-1])\n",
    "print('Sampling frequency (samples/s): ', fs)\n",
    "\n",
    "#Playing word (Reproduce word)\n",
    "ipd.Audio(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fba9b",
   "metadata": {},
   "source": [
    "# Spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f546b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphic Spectrogram \n",
    "\n",
    "plt.rcParams['figure.figsize'] = 14,5\n",
    "plt.pcolormesh(t, f[:450], S1[:450][:])\n",
    "plt.title(\"Spectrogram\")\n",
    "plt.xlabel('time(s)')\n",
    "plt.ylabel('frequency(Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro ButterWord\n",
    "\n",
    "wn = 1500/(fs/2)\n",
    "b3,a3 = butter(4, wn)\n",
    "#Apply the filter\n",
    "word_filt = lfilter(b3,a3,word)\n",
    "\n",
    "plt.plot(word_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a57373",
   "metadata": {},
   "source": [
    "# Show Word Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot word Filtered and only positive part\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 16,5\n",
    "#plot(audio1,'r')\n",
    "plt.plot(np.absolute(word_filt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbef5a1",
   "metadata": {},
   "source": [
    "# Segment Audio\n",
    "\n",
    "Do the first segmentation in order to isolate the desired word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17916c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Threshold for the word phonems\n",
    "\n",
    "results = [1 if item > 0.001*1e8 else 0 for item in audio1_filt**2]\n",
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "x1 = x2 = 0\n",
    "flag = False\n",
    "chunks = []\n",
    "coordinates = []\n",
    "zeros_list = []\n",
    "silence_len = 2000\n",
    "min_len = 5000\n",
    "\n",
    "plt.plot(results)\n",
    "for i, result in enumerate(results):\n",
    "    # First signal rise\n",
    "    if(flag == False and result == 1 and x1 == 0):\n",
    "        flag = True\n",
    "        x1 = i\n",
    "    # Check if fall is permanent\n",
    "    if(flag == True):\n",
    "        if(result == 0):\n",
    "            zeros_list.append(result)\n",
    "        else:\n",
    "            zeros_list = []\n",
    "    # Signal fall\n",
    "    if(flag == True and len(zeros_list) >= silence_len and x2 == 0):\n",
    "        flag = False\n",
    "        x2 = i - len(zeros_list)\n",
    "        # If data is valid, save it in list\n",
    "        if(not x2-x1 <= min_len):\n",
    "            chunks.append(results[x1:x2+1])\n",
    "            coordinates.append([x1, x2])\n",
    "            plt.plot([x1, x1], [0, 1], [x2, x2], [0, 1], marker='o')\n",
    "        # Reset to initial state\n",
    "        x1 = x2 = 0\n",
    "\n",
    "print(f'# of chunks detected: {len(chunks)}')\n",
    "\n",
    "pt1 = coordinates[0]\n",
    "try:\n",
    "    pt2 = coordinates[1]\n",
    "    div_ptn = ((pt2[0] - pt1[1]) / 2) + pt1[1]\n",
    "except:\n",
    "    div_ptn = ((pt1[1] + pt1[0]) / 2)\n",
    "    \n",
    "# Draw dividing line\n",
    "plt.plot([div_ptn, div_ptn], [0, 1], marker='o', color=\"black\")\n",
    "print(pt1[0], pt1[1])\n",
    "print(pt1[1] - pt1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ebe53",
   "metadata": {},
   "source": [
    "# Split Word\n",
    "\n",
    "Split the word in two phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make segmentation point integer\n",
    "div_ptn = round(div_ptn)\n",
    "\n",
    "# Fix-sized segmentation (breaks a signal into non-overlapping segments)\n",
    "signal = audio1 / (2**15)\n",
    "signal_len = len(signal)\n",
    "segment_size_t = 1 # segment size in seconds\n",
    "segment_size = segment_size_t * fs  # segment size in samples\n",
    "\n",
    "# Break signal into list of segments in a single-line Python code\n",
    "segment1 = audio1[:div_ptn]\n",
    "segment2 = audio1[div_ptn:]\n",
    "segments = [segment1, segment2]\n",
    "\n",
    "# Find out the number of Segments\n",
    "n = len(segments)\n",
    "\n",
    "# Acess the first chunk of the audio\n",
    "samples = segments[0]\n",
    "samples = np.array(samples)\n",
    "\n",
    "# Process each chunk\n",
    "# Save each segment in a seperate filename\n",
    "for iS, s in enumerate(segments):\n",
    "    write('Word Detection/WD_data/'+filename+'_{0:d}.wav'.format(segment_size_t * iS, segment_size_t * (iS + 1)), fs, (s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a51c5",
   "metadata": {},
   "source": [
    "# MFCC's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c750fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = segments[0] #First phoneme \n",
    "\n",
    "#Play Audio\n",
    "ipd.Audio(filename)\n",
    "\n",
    "#Calculate MFCC'S\n",
    "mfccs = librosa.feature.mfcc(signal, sr=fs, n_mfcc=42, n_fft = 1024, hop_length = 50,\n",
    "                                n_mels = 1000,  fmin = 10, fmax = 4000)\n",
    "\n",
    "#Normalize MFCC's Results (Y axis)\n",
    "mfccs = sklearn.preprocessing.scale(mfccs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize MFCC \n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "sr = fs\n",
    "librosa.display.specshow(mfccs[1:],x_axis='time',sr=sr)\n",
    "plt.colorbar(format=\"%+2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc54d79c",
   "metadata": {},
   "source": [
    "# Training and Classificator\n",
    "\n",
    "## Read and calculate MFCC for all segmented phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f435314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfccs(signal, fs):\n",
    "    \n",
    "    #Calculate MFCCs\n",
    "    mfccs = librosa.feature.mfcc(signal, sr=fs, n_mfcc=200, n_fft = 1024, hop_length = 50, n_mels = 1000,  fmin = 10, fmax = 4000)\n",
    "    \n",
    "    # Calculate average\n",
    "    mfccs = np.average(mfccs, axis=1)\n",
    "    #mfccs = np.average(np.average(mfccs, axis=1))\n",
    "    # Make it into a one-dimensional array\n",
    "    mfccs = mfccs.flatten()\n",
    "    mfccs = mfccs.tolist()\n",
    "    return mfccs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "936b2ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phonemes: ['ca', 'pa', 'sa', 'ta', 've', 'cha', 'chu', 'va', 'far', 'da', 'la', 'ri']\n",
      "# of phonemes: 12\n"
     ]
    }
   ],
   "source": [
    "#directory = 'C:/Users/lemos/PDS/TP/Word Detection/WD_data/'\n",
    "directory = 'C:/Users/Dasil/1. Processamento Digital do Sinal/Project/Word Detection/WD_data/'\n",
    "\n",
    "hope = False\n",
    "mfcc_data = []\n",
    "phoneme_list = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    \n",
    "    # Get audio file\n",
    "    filename = os.path.join(directory, file)\n",
    "    \n",
    "    # load Audio for Signal\n",
    "    signal, fs = librosa.load(filename)\n",
    "    \n",
    "    # Get mfccs from audio\n",
    "    mfccs = get_mfccs(signal, fs)\n",
    "    mfccs.insert(1,mfccs[0])\n",
    "    #mfccs = mfccs[:18]\n",
    "        \n",
    "    #Calculate Cepstrung and Power Spectrum\n",
    "    #ceps, spec = real_cepstrum(signal, n=None)\n",
    "    #N = signal.shape[0]\n",
    "\n",
    "    #Power Specturm\n",
    "    #power_spec = np.abs(spec[:N//2])**2\n",
    "    #index = np.where(power_spec == np.max(power_spec))\n",
    "    #mfccs.append(index[0][0])\n",
    "    \n",
    "    #Calculate Zero Cross Rate\n",
    "    frameSize = 256\n",
    "    overlap = 0\n",
    "    #zcr = ZCR(signal, frameSize, overlap)\n",
    "    #mfccs.append(np.max(zcr))\n",
    "\n",
    "    #Calculate Cepstrum\n",
    "    #abs_ceps = np.abs(ceps[:N//2])**2\n",
    "    #mfccs.append(round(np.max(abs_ceps)))        \n",
    "        \n",
    "    # Remove the first coeficient\n",
    "    mfccs.pop(0)\n",
    "\n",
    "    # Delete the features of some mfcc coeficients because they are not needed.\n",
    "    #mfccs = mfccs[:12]\n",
    "    #mfccs = mfccs[25:]\n",
    "    mfccs = mfccs[:18]\n",
    "    \n",
    "    # Insert label\n",
    "    file = file.replace('.wav', '')\n",
    "    file_parts = file.split('_')\n",
    "    word = file_parts[1]\n",
    "    if (len(word) > 4):\n",
    "        if(file_parts[-1] == '0'):\n",
    "            phoneme = word[0:3]\n",
    "        else:\n",
    "            phoneme = word[3:]\n",
    "    else:\n",
    "        if(file_parts[-1] == '0'):\n",
    "            phoneme = word[0:2]\n",
    "        else:\n",
    "            phoneme = word[2:]\n",
    "    phoneme_list.append(phoneme)\n",
    "    mfccs.insert(0, phoneme)\n",
    "    mfcc_data.append(mfccs) \n",
    "    \n",
    "# Remove duplicates\n",
    "phoneme_list = list(dict.fromkeys(phoneme_list))\n",
    "print(f'Phonemes: {phoneme_list}')\n",
    "print(f'# of phonemes: {len(phoneme_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c973bf6",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8be3878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1333.824829</td>\n",
       "      <td>-13.344981</td>\n",
       "      <td>-8.673552</td>\n",
       "      <td>16.886024</td>\n",
       "      <td>-21.717295</td>\n",
       "      <td>-6.735435</td>\n",
       "      <td>7.127103</td>\n",
       "      <td>-9.960970</td>\n",
       "      <td>13.504705</td>\n",
       "      <td>-24.204016</td>\n",
       "      <td>0.162556</td>\n",
       "      <td>-5.730914</td>\n",
       "      <td>-3.007067</td>\n",
       "      <td>-9.956505</td>\n",
       "      <td>6.730868</td>\n",
       "      <td>-13.654622</td>\n",
       "      <td>3.832473</td>\n",
       "      <td>-3.653511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>-2047.637817</td>\n",
       "      <td>41.290699</td>\n",
       "      <td>2.112942</td>\n",
       "      <td>17.034643</td>\n",
       "      <td>-3.494052</td>\n",
       "      <td>4.061397</td>\n",
       "      <td>-2.206772</td>\n",
       "      <td>4.460487</td>\n",
       "      <td>8.158010</td>\n",
       "      <td>-8.500338</td>\n",
       "      <td>2.002730</td>\n",
       "      <td>3.357300</td>\n",
       "      <td>-2.801673</td>\n",
       "      <td>1.526366</td>\n",
       "      <td>-1.395955</td>\n",
       "      <td>-0.560099</td>\n",
       "      <td>-0.096373</td>\n",
       "      <td>-3.564867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-1358.306396</td>\n",
       "      <td>-27.451931</td>\n",
       "      <td>1.506319</td>\n",
       "      <td>11.318576</td>\n",
       "      <td>-17.887531</td>\n",
       "      <td>0.313432</td>\n",
       "      <td>3.328127</td>\n",
       "      <td>-7.138087</td>\n",
       "      <td>9.887049</td>\n",
       "      <td>-14.652740</td>\n",
       "      <td>5.700831</td>\n",
       "      <td>-11.412127</td>\n",
       "      <td>4.718484</td>\n",
       "      <td>-9.180216</td>\n",
       "      <td>5.071042</td>\n",
       "      <td>-9.899351</td>\n",
       "      <td>2.345407</td>\n",
       "      <td>-1.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-1522.450317</td>\n",
       "      <td>34.833778</td>\n",
       "      <td>-13.227207</td>\n",
       "      <td>15.833639</td>\n",
       "      <td>-12.494040</td>\n",
       "      <td>-1.964486</td>\n",
       "      <td>-1.604259</td>\n",
       "      <td>-0.622769</td>\n",
       "      <td>11.451959</td>\n",
       "      <td>-15.049759</td>\n",
       "      <td>1.468158</td>\n",
       "      <td>0.493478</td>\n",
       "      <td>-2.819326</td>\n",
       "      <td>-2.246803</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-4.346762</td>\n",
       "      <td>1.448318</td>\n",
       "      <td>-2.369789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1430.136230</td>\n",
       "      <td>-18.182390</td>\n",
       "      <td>34.160870</td>\n",
       "      <td>23.533379</td>\n",
       "      <td>-23.276001</td>\n",
       "      <td>-13.209202</td>\n",
       "      <td>7.364529</td>\n",
       "      <td>-23.842701</td>\n",
       "      <td>7.921567</td>\n",
       "      <td>-14.682115</td>\n",
       "      <td>13.051703</td>\n",
       "      <td>-13.635929</td>\n",
       "      <td>6.975810</td>\n",
       "      <td>-6.515664</td>\n",
       "      <td>-11.448876</td>\n",
       "      <td>-3.455009</td>\n",
       "      <td>-10.726481</td>\n",
       "      <td>0.381645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>9</td>\n",
       "      <td>-1713.436035</td>\n",
       "      <td>-14.930456</td>\n",
       "      <td>28.081966</td>\n",
       "      <td>-3.269842</td>\n",
       "      <td>22.599226</td>\n",
       "      <td>-7.594925</td>\n",
       "      <td>-0.150675</td>\n",
       "      <td>12.487407</td>\n",
       "      <td>-0.331729</td>\n",
       "      <td>2.393736</td>\n",
       "      <td>-0.333911</td>\n",
       "      <td>3.020628</td>\n",
       "      <td>-2.268018</td>\n",
       "      <td>-1.279858</td>\n",
       "      <td>2.308494</td>\n",
       "      <td>-1.566175</td>\n",
       "      <td>-2.876453</td>\n",
       "      <td>2.377063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>7</td>\n",
       "      <td>-1679.615601</td>\n",
       "      <td>-61.792160</td>\n",
       "      <td>66.527222</td>\n",
       "      <td>-16.308260</td>\n",
       "      <td>26.346516</td>\n",
       "      <td>-12.518517</td>\n",
       "      <td>3.860537</td>\n",
       "      <td>-1.688408</td>\n",
       "      <td>-0.341534</td>\n",
       "      <td>-0.289854</td>\n",
       "      <td>-1.569777</td>\n",
       "      <td>4.417487</td>\n",
       "      <td>-5.646485</td>\n",
       "      <td>3.351714</td>\n",
       "      <td>-2.117579</td>\n",
       "      <td>-3.489269</td>\n",
       "      <td>-1.272613</td>\n",
       "      <td>-2.289502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>9</td>\n",
       "      <td>-1713.436035</td>\n",
       "      <td>-14.930456</td>\n",
       "      <td>28.081966</td>\n",
       "      <td>-3.269842</td>\n",
       "      <td>22.599226</td>\n",
       "      <td>-7.594925</td>\n",
       "      <td>-0.150675</td>\n",
       "      <td>12.487407</td>\n",
       "      <td>-0.331729</td>\n",
       "      <td>2.393736</td>\n",
       "      <td>-0.333911</td>\n",
       "      <td>3.020628</td>\n",
       "      <td>-2.268018</td>\n",
       "      <td>-1.279858</td>\n",
       "      <td>2.308494</td>\n",
       "      <td>-1.566175</td>\n",
       "      <td>-2.876453</td>\n",
       "      <td>2.377063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>7</td>\n",
       "      <td>-1739.948364</td>\n",
       "      <td>-48.406658</td>\n",
       "      <td>67.691559</td>\n",
       "      <td>-15.592954</td>\n",
       "      <td>23.433620</td>\n",
       "      <td>-7.664473</td>\n",
       "      <td>2.089020</td>\n",
       "      <td>-2.396087</td>\n",
       "      <td>5.130900</td>\n",
       "      <td>-1.910935</td>\n",
       "      <td>0.549396</td>\n",
       "      <td>5.342144</td>\n",
       "      <td>-4.116349</td>\n",
       "      <td>3.726255</td>\n",
       "      <td>-0.397541</td>\n",
       "      <td>-6.060598</td>\n",
       "      <td>3.774299</td>\n",
       "      <td>-6.489661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>9</td>\n",
       "      <td>-1671.204590</td>\n",
       "      <td>2.713111</td>\n",
       "      <td>31.422152</td>\n",
       "      <td>-0.210326</td>\n",
       "      <td>20.168264</td>\n",
       "      <td>-0.052545</td>\n",
       "      <td>-2.348566</td>\n",
       "      <td>10.752408</td>\n",
       "      <td>5.127505</td>\n",
       "      <td>-0.705427</td>\n",
       "      <td>2.967264</td>\n",
       "      <td>-0.247085</td>\n",
       "      <td>-0.120439</td>\n",
       "      <td>-1.115839</td>\n",
       "      <td>0.144844</td>\n",
       "      <td>-0.805488</td>\n",
       "      <td>-2.134712</td>\n",
       "      <td>2.821779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0            1          2          3          4          5          6   \\\n",
       "0     0 -1333.824829 -13.344981  -8.673552  16.886024 -21.717295  -6.735435   \n",
       "1     6 -2047.637817  41.290699   2.112942  17.034643  -3.494052   4.061397   \n",
       "2     0 -1358.306396 -27.451931   1.506319  11.318576 -17.887531   0.313432   \n",
       "3     6 -1522.450317  34.833778 -13.227207  15.833639 -12.494040  -1.964486   \n",
       "4     0 -1430.136230 -18.182390  34.160870  23.533379 -23.276001 -13.209202   \n",
       "...  ..          ...        ...        ...        ...        ...        ...   \n",
       "1135  9 -1713.436035 -14.930456  28.081966  -3.269842  22.599226  -7.594925   \n",
       "1136  7 -1679.615601 -61.792160  66.527222 -16.308260  26.346516 -12.518517   \n",
       "1137  9 -1713.436035 -14.930456  28.081966  -3.269842  22.599226  -7.594925   \n",
       "1138  7 -1739.948364 -48.406658  67.691559 -15.592954  23.433620  -7.664473   \n",
       "1139  9 -1671.204590   2.713111  31.422152  -0.210326  20.168264  -0.052545   \n",
       "\n",
       "            7          8          9          10         11         12  \\\n",
       "0     7.127103  -9.960970  13.504705 -24.204016   0.162556  -5.730914   \n",
       "1    -2.206772   4.460487   8.158010  -8.500338   2.002730   3.357300   \n",
       "2     3.328127  -7.138087   9.887049 -14.652740   5.700831 -11.412127   \n",
       "3    -1.604259  -0.622769  11.451959 -15.049759   1.468158   0.493478   \n",
       "4     7.364529 -23.842701   7.921567 -14.682115  13.051703 -13.635929   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "1135 -0.150675  12.487407  -0.331729   2.393736  -0.333911   3.020628   \n",
       "1136  3.860537  -1.688408  -0.341534  -0.289854  -1.569777   4.417487   \n",
       "1137 -0.150675  12.487407  -0.331729   2.393736  -0.333911   3.020628   \n",
       "1138  2.089020  -2.396087   5.130900  -1.910935   0.549396   5.342144   \n",
       "1139 -2.348566  10.752408   5.127505  -0.705427   2.967264  -0.247085   \n",
       "\n",
       "            13        14         15         16         17        18  \n",
       "0    -3.007067 -9.956505   6.730868 -13.654622   3.832473 -3.653511  \n",
       "1    -2.801673  1.526366  -1.395955  -0.560099  -0.096373 -3.564867  \n",
       "2     4.718484 -9.180216   5.071042  -9.899351   2.345407 -1.999251  \n",
       "3    -2.819326 -2.246803   0.000085  -4.346762   1.448318 -2.369789  \n",
       "4     6.975810 -6.515664 -11.448876  -3.455009 -10.726481  0.381645  \n",
       "...        ...       ...        ...        ...        ...       ...  \n",
       "1135 -2.268018 -1.279858   2.308494  -1.566175  -2.876453  2.377063  \n",
       "1136 -5.646485  3.351714  -2.117579  -3.489269  -1.272613 -2.289502  \n",
       "1137 -2.268018 -1.279858   2.308494  -1.566175  -2.876453  2.377063  \n",
       "1138 -4.116349  3.726255  -0.397541  -6.060598   3.774299 -6.489661  \n",
       "1139 -0.120439 -1.115839   0.144844  -0.805488  -2.134712  2.821779  \n",
       "\n",
       "[1140 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset loading\n",
    "df = pd.DataFrame(mfcc_data)\n",
    "\n",
    "x = df.iloc[:,1:] # MFCC features\n",
    "y = df.iloc[:,0] # Phoneme label\n",
    "\n",
    "# Label changed to number once\n",
    "label = set(y)\n",
    "label_list = list(label)\n",
    "label_list.sort()\n",
    "for i in range(len(label_list)):\n",
    "    y[y == label_list[i]] = i\n",
    "y = np.array(y, dtype = \"int\")\n",
    "\n",
    "# Preview dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806428d",
   "metadata": {},
   "source": [
    "# Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02414a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (798, 18)\n",
      "Test: (342, 18)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train result</th>\n",
       "      <th>Test result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>81.33</td>\n",
       "      <td>71.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poly</th>\n",
       "      <td>77.07</td>\n",
       "      <td>66.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF</th>\n",
       "      <td>85.71</td>\n",
       "      <td>76.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>82.33</td>\n",
       "      <td>67.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Train result  Test result\n",
       "Linear         81.33        71.05\n",
       "Poly           77.07        66.37\n",
       "RBF            85.71        76.02\n",
       "KNN            82.33        67.25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the train data and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)\n",
    "print(f'Train: {x_train.shape}\\nTest: {x_test.shape}\\n')\n",
    "\n",
    "# Data standardization\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)\n",
    "\n",
    "# Instantiate an SVM\n",
    "model_linear = SVC(kernel='linear', random_state=1)\n",
    "model_poly = SVC(kernel='poly', random_state= 1)\n",
    "model_rbf = SVC(kernel='rbf', random_state=1)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit models\n",
    "model_linear.fit(x_train_std, y_train)\n",
    "model_poly.fit(x_train_std, y_train)\n",
    "model_rbf.fit(x_train_std, y_train)\n",
    "model_knn.fit(x_train_std, y_train)\n",
    "\n",
    "# ===== Train data =====\n",
    "# Predictions\n",
    "pred_linear_train = model_linear.predict(x_train_std)\n",
    "pred_poly_train = model_poly.predict(x_train_std)\n",
    "pred_rbf_train = model_rbf.predict(x_train_std)\n",
    "pred_knn_train = model_knn.predict(x_train_std)\n",
    "# Accuracy scores\n",
    "accuracy_linear_train = accuracy_score(y_train, pred_linear_train)\n",
    "accuracy_poly_train = accuracy_score(y_train, pred_poly_train)\n",
    "accuracy_rbf_train = accuracy_score(y_train, pred_rbf_train)\n",
    "accuracy_knn_train = accuracy_score(y_train, pred_knn_train)\n",
    "\n",
    "#print('Train result')\n",
    "#print(f'Linear : {int(accuracy_linear_train*100)}%')\n",
    "#print(f'Poly : {int(accuracy_poly_train*100)}%')\n",
    "#print(f'RBF : {int(accuracy_rbf_train*100)}%')\n",
    "#print(\"-\" * 15)\n",
    "\n",
    "# ===== Test data =====\n",
    "# Predictions\n",
    "pred_linear_test = model_linear.predict(x_test_std)\n",
    "pred_poly_test = model_poly.predict(x_test_std)\n",
    "pred_rbf_test = model_rbf.predict(x_test_std)\n",
    "pred_knn_test = model_knn.predict(x_test_std)\n",
    "# Accuracy scores\n",
    "accuracy_linear_test = accuracy_score(y_test, pred_linear_test)\n",
    "accuracy_poly_test = accuracy_score(y_test, pred_poly_test)\n",
    "accuracy_rbf_test = accuracy_score(y_test, pred_rbf_test)\n",
    "accuracy_knn_test = accuracy_score(y_test, pred_knn_test)\n",
    "\n",
    "#print('Test result')\n",
    "#print(f'Linear : {int(accuracy_linear_test*100)}%')\n",
    "#print(f'Poly : {int(accuracy_poly_test*100)}%')\n",
    "#print(f'RBF : {int(accuracy_rbf_test*100)}%')\n",
    "\n",
    "# Create dataframe\n",
    "data = {'Train result':[accuracy_linear_train*100, accuracy_poly_train*100, accuracy_rbf_train*100, accuracy_knn_train*100],\n",
    "        'Test result': [accuracy_linear_test*100, accuracy_poly_test*100, accuracy_rbf_test*100, accuracy_knn_test*100]}\n",
    "df_results = pd.DataFrame(data)\n",
    "# Change the row indexes\n",
    "df_results.index = ['Linear', 'Poly', 'RBF', 'KNN']\n",
    "df_results.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6318049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear: dada\n",
      "Poly: dada\n",
      "RBF: cada\n",
      "KNN: veda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>Poly</th>\n",
       "      <th>RBF</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dada</td>\n",
       "      <td>dada</td>\n",
       "      <td>cada</td>\n",
       "      <td>veda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Linear  Poly   RBF   KNN\n",
       "0   dada  dada  cada  veda"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'J_chuva_01'\n",
    "\n",
    "phoneme1 = f'C:/Users/Dasil/1. Processamento Digital do Sinal/Project/Word Detection/WD_data/{file}_0.wav' \n",
    "phoneme2 = f'C:/Users/Dasil/1. Processamento Digital do Sinal/Project/Word Detection/WD_data/{file}_1.wav'\n",
    "\n",
    "\n",
    "# load Audio for Signal\n",
    "signal_phoneme1, fs = librosa.load(phoneme1)\n",
    "signal_phoneme2, fs = librosa.load(phoneme2)\n",
    "\n",
    "#Calculate MFCCs\n",
    "mfccs_phoneme1 = get_mfccs(signal_phoneme1, fs)\n",
    "mfccs_phoneme2 = get_mfccs(signal_phoneme2, fs)\n",
    "\n",
    "mfccs_phoneme1.pop(0)\n",
    "mfccs_phoneme2.pop(0)\n",
    "mfccs_phoneme1 = mfccs_phoneme1[:18]\n",
    "mfccs_phoneme2 = mfccs_phoneme2[:18]\n",
    "\n",
    "# #Calculate Cepstrung and Power Spectrum\n",
    "# ceps1, spec1 = real_cepstrum(signal_phoneme1, n=None)\n",
    "# N1 = signal_phoneme1.shape[0]\n",
    "# ceps2, spec2 = real_cepstrum(signal_phoneme2, n=None)\n",
    "# N2 = signal_phoneme2.shape[0]\n",
    "\n",
    "# #Power Specturm\n",
    "# power_spec1 = np.abs(spec1[:N//2])**2\n",
    "# index1 = np.where(power_spec1 == np.max(power_spec1))\n",
    "# mfccs_phoneme1.append(index1[0][0])\n",
    "\n",
    "# power_spec2 = np.abs(spec2[:N//2])**2\n",
    "# index2 = np.where(power_spec2 == np.max(power_spec2))\n",
    "# mfccs_phoneme2.append(index2[0][0])\n",
    "\n",
    "# #Calculate Zero Cross Rate\n",
    "# frameSize = 256\n",
    "# overlap = 0\n",
    "# zcr1 = ZCR(signal_phoneme1, frameSize, overlap)\n",
    "# mfccs_phoneme1.append(np.max(zcr1))\n",
    "\n",
    "# zcr2 = ZCR(signal_phoneme2, frameSize, overlap)\n",
    "# mfccs_phoneme2.append(np.max(zcr2))\n",
    "\n",
    "# #Calculate Cepstrum\n",
    "# abs_ceps1 = np.abs(ceps1[:N//2])**2\n",
    "# mfccs_phoneme1.append(round(np.max(abs_ceps1)))\n",
    "\n",
    "# abs_ceps2 = np.abs(ceps2[:N//2])**2\n",
    "# mfccs_phoneme2.append(round(np.max(abs_ceps2)))\n",
    "\n",
    "\n",
    "df_phoneme1 = pd.DataFrame(mfccs_phoneme1).T\n",
    "df_phoneme2 = pd.DataFrame(mfccs_phoneme2).T\n",
    "#df\n",
    "\n",
    "#Data standardization\n",
    "sc = StandardScaler()\n",
    "sc.fit(df_phoneme1)\n",
    "x_std_phoneme1 = sc.transform(df_phoneme1)\n",
    "sc.fit(df_phoneme2)\n",
    "x_std_phoneme2 = sc.transform(df_phoneme2)\n",
    "\n",
    "pred_linear_phoneme1 = model_linear.predict(x_std_phoneme1)\n",
    "pred_poly_phoneme1 = model_poly.predict(x_std_phoneme1)\n",
    "pred_rbf_phoneme1 = model_rbf.predict(x_std_phoneme1)\n",
    "pred_knn_phoneme1 = model_knn.predict(x_std_phoneme1)\n",
    "\n",
    "pred_linear_phoneme2 = model_linear.predict(x_std_phoneme2)\n",
    "pred_poly_phoneme2 = model_poly.predict(x_std_phoneme2)\n",
    "pred_rbf_phoneme2 = model_rbf.predict(x_std_phoneme2)\n",
    "pred_knn_phoneme2 = model_knn.predict(x_std_phoneme2)\n",
    "\n",
    "data = {'Linear':[phoneme_list[int(pred_linear_phoneme1)]+phoneme_list[int(pred_linear_phoneme2)]],\n",
    "        'Poly':[phoneme_list[int(pred_poly_phoneme1)]+phoneme_list[int(pred_linear_phoneme2)]],\n",
    "        'RBF': [phoneme_list[int(pred_rbf_phoneme1)]+phoneme_list[int(pred_linear_phoneme2)]],\n",
    "        'KNN': [phoneme_list[int(pred_knn_phoneme1)]+phoneme_list[int(pred_linear_phoneme2)]]}\n",
    "\n",
    "df_models = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(f'Linear: {phoneme_list[int(pred_linear_phoneme1)]+phoneme_list[int(pred_linear_phoneme2)]}')\n",
    "print(f'Poly: {phoneme_list[int(pred_poly_phoneme1)]+phoneme_list[int(pred_linear_phoneme2)]}')\n",
    "print(f'RBF: {phoneme_list[int(pred_rbf_phoneme1)]+phoneme_list[int(pred_linear_phoneme2)]}')\n",
    "print(f'KNN: {phoneme_list[int(pred_knn_phoneme1)]+phoneme_list[int(pred_linear_phoneme2)]}')\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data standardization\n",
    "sc = StandardScaler()\n",
    "sc.fit(df)\n",
    "x_std = sc.transform(df)\n",
    "\n",
    "pred_linear_test = model_linear.predict(x_std)\n",
    "pred_poly_test = model_poly.predict(x_std)\n",
    "pred_rbf_test = model_rbf.predict(x_std)\n",
    "pred_knn_test = model_knn.predict(x_std)\n",
    "\n",
    "\n",
    "data = {'Linear':[phoneme_list[int(pred_linear_test)]],\n",
    "        'Poly':[phoneme_list[int(pred_poly_test)]],\n",
    "        'RBF': [phoneme_list[int(pred_rbf_test)]],\n",
    "        'KNN': [phoneme_list[int(pred_knn_test)]]}\n",
    "\n",
    "df_models = pd.DataFrame(data) \n",
    "df_models\n",
    "#print(phoneme_list[int(pred_linear_test)])\n",
    "#print(phoneme_list[int(pred_poly_test)])\n",
    "#print(phoneme_list[int(pred_rbf_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05980544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "models = {\n",
    "        'LogisticRegression'     : LogisticRegression(),\n",
    "        'SVM'                    : SVC(),\n",
    "        'RandomForestClassifier' : RandomForestClassifier(),\n",
    "        'KNN'                    : KNeighborsClassifier()}\n",
    "\n",
    "hyper = {\n",
    "        \n",
    "        'LogisticRegression':{\n",
    "                                    'penalty'     : ['l2'],\n",
    "                                    'C'           : np.logspace(0, 4, 10),\n",
    "                                    'solver'      : ['lbfgs', 'liblinear', 'saga'],\n",
    "                                    'class_weight': ['balanced'],\n",
    "                                    'random_state': [0]},\n",
    "        \n",
    "        'SVM':{\n",
    "                                    'C'           : [0.01, 0.1, 1, 10, 100, 1000],\n",
    "                                    'gamma'       : [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                                    'kernel'      : ['rbf', 'linear'],\n",
    "                                    'class_weight': ['balanced'],\n",
    "                                    'random_state': [0]},\n",
    "        \n",
    "        'RandomForestClassifier':{\n",
    "                                    'max_depth': [2, 3, 4],\n",
    "                                    'max_features': [2, 3, 4, 'auto', 'sqrt'],\n",
    "                                    'n_estimators': [10, 100, 500, 1000],\n",
    "                                    'class_weight': ['balanced'],\n",
    "                                    'random_state': [0]},\n",
    "       \n",
    "        'KNN':{\n",
    "                                    'n_neighbors': [5, 10, 15, 20],\n",
    "                                    'weights': ['uniform', 'distance']}\n",
    "                              \n",
    "                              \n",
    "    }\n",
    "\n",
    "\n",
    "for model_name in models.keys():\n",
    "\n",
    "    # Model selection\n",
    "    clf    = models[model_name]\n",
    "    params = hyper[model_name]\n",
    "\n",
    "    # Pipeline (standarization + classifier)\n",
    "    pipe = Pipeline([ ( 'scaler', StandardScaler() ), ( 'clf', clf ) ])\n",
    "\n",
    "    # Gridsearch cross-validation\n",
    "    grid = GridSearchCV(estimator = clf, param_grid = params, cv = 5, return_train_score = True)\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    # Gridsearch cross-validation results\n",
    "    best_param                  = grid.best_params_\n",
    "    best_param_test_score_mean  = grid.cv_results_['mean_test_score'][grid.best_index_]\n",
    "    best_param_test_score_std   = grid.cv_results_['std_test_score'][grid.best_index_]\n",
    "    best_param_train_score_mean = grid.cv_results_['mean_train_score'][grid.best_index_]\n",
    "    best_param_train_score_std  = grid.cv_results_['std_train_score'][grid.best_index_]\n",
    "    \n",
    "print(best_param)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf580ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hunga_bunga import HungaBungaClassifier, HungaBungaRegressor\n",
    "\n",
    "clf = HungaBungaClassifier()\n",
    "clf.fit(x,y)\n",
    "clf.prefit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b60b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
