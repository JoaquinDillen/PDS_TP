{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37a59d5",
   "metadata": {},
   "source": [
    "#  Data Analysis and Results Collection\n",
    "\n",
    "This file is for automaticly output all the analysis for all dataset at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c9fcb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "040f08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import pyAudioAnalysis\n",
    "import pydub\n",
    "import ffmpeg\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "\n",
    "from numpy import sin, cos, pi, linspace, arange, log10, absolute\n",
    "from numpy.random import randn\n",
    "from scipy.signal import lfilter, lfilter_zi, filtfilt, butter, freqz, welch\n",
    "from scipy.io.wavfile import read , write\n",
    "from scipy.signal import spectrogram\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import ylabel, xlabel\n",
    "from matplotlib.pyplot import plot, legend, show, grid, figure, savefig#, hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6be5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Words\n",
    "words = [\"_chata_0\",\"_chapa_0\",\"_chave_0\",\"_lata_0\",\"_lapa_0\",\"_lava_0\",\"_casa_0\",\"_capa_0\",\"_cave_0\",\"_cata_0\",\"_chuta_0\",\"_chupa_0\",\"_chuva_0\",\"_farta_0\",\"_farpa_0\",\"_farda_0\",\"_ripa_0\",\"_rita_0\",\"_rica_0\"]\n",
    "\n",
    "#List of Dataset versions\n",
    "d = {\"one\": 1, \"two\": 2}\n",
    "iterable = d.keys()\n",
    "\n",
    "#List of Phonemes \n",
    "phoneme = [\"_0\", \"_1\"]\n",
    "\n",
    "#List of people\n",
    "p = ['A','J','N']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29a9fb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segments = []\n",
    "errors = 0\n",
    "\n",
    "for y in words:\n",
    "    for item in iterable:      \n",
    "        for x in p:\n",
    "            for t in phoneme:\n",
    "\n",
    "                # Write file path\n",
    "                l = str(d[item])\n",
    "                os.chdir(r'C:\\Users\\Dasil\\1. Processamento Digital do Sinal\\Project')\n",
    "                \n",
    "                #MFCC Analysis\n",
    "                filename = 'audio/WD_data/'+x+y+l+t+'.wav' #for Test DataSet\n",
    "                signal, fs = librosa.load(filename)\n",
    "                \n",
    "                #print(filename)\n",
    "                \n",
    "                # Some Audio Errors, the solution maybe in here \n",
    "                # https://stackoverflow.com/questions/68130038/valueerror-input-signal-length-2-is-too-small-to-resample-from-44100-16000\n",
    "                \n",
    "                sr = fs\n",
    "                \n",
    "                #signal.shape\n",
    "                #mfccs = librosa.feature.mfcc(signal, sr=fs, n_mfcc=40, n_fft = 1024, hop_length = 50, n_mels = 130,  fmin = 10, fmax = 4000)         \n",
    "                mfccs = librosa.feature.mfcc(signal, sr=fs, n_mfcc=40, n_fft = 1024, hop_length = 200, n_mels = 130,  fmin = 10, fmax = 4000)         \n",
    "\n",
    "\n",
    "                #Normalyse Y scale\n",
    "                mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "\n",
    "                #Visualie MFCC \n",
    "                plt.figure(figsize=(14,4))\n",
    "                #librosa.display.specshow(mfccs[1:][10:],x_axis='time',sr=sr)\n",
    "                librosa.display.specshow(mfccs[25:][:],x_axis='time',sr=sr)\n",
    "                plt.colorbar(format=\"%+2f\")\n",
    "                plt.plot()\n",
    "\n",
    "                plt.savefig('Word Detection/MFCCS_ID/'+x+y+l+t+'.jpeg')\n",
    "                  \n",
    "                #Clean the graphics\n",
    "                plt.close()\n",
    "                plt.cla()\n",
    "                plt.clf()\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
