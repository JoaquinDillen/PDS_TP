{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37a59d5",
   "metadata": {},
   "source": [
    "#  Data Analysis and Results Collection\n",
    "\n",
    "This file is for automaticly output all the analysis for all dataset at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9fcb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040f08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import pyAudioAnalysis\n",
    "import pydub\n",
    "import ffmpeg\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "\n",
    "from numpy import sin, cos, pi, linspace, arange, log10, absolute\n",
    "from numpy.random import randn\n",
    "from scipy.signal import lfilter, lfilter_zi, filtfilt, butter, freqz, welch\n",
    "from scipy.io.wavfile import read , write\n",
    "from scipy.signal import spectrogram\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import ylabel, xlabel\n",
    "from matplotlib.pyplot import plot, legend, show, grid, figure, savefig#, hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ea7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cepstrum and Power Spectrum\n",
    "\n",
    "def real_cepstrum(x, n=None):\n",
    "# Compute the real cepstrum of a real sequence\n",
    "#    x : ndarray\n",
    "#        Real sequence to compute real cepstrum of.\n",
    "#    n : {None, int}, optional\n",
    "#        Length of the Fourier transform.\n",
    "#    Returns\n",
    "#    -------\n",
    "#    ceps: ndarray\n",
    "#        The real cepstrum.\n",
    "\n",
    "    spectrum = np.abs(np.fft.fft(x, n=n))**2\n",
    "    ceps = np.fft.ifft(np.log(spectrum))\n",
    "\n",
    "    return ceps, spectrum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero Crossing Rate\n",
    "\n",
    "def ZCR(samples, frameSize, overlap):\n",
    "    wlen = len(samples)\n",
    "    step = frameSize - overlap\n",
    "    frameNum = math.ceil(wlen/step)\n",
    "    zcr = np.zeros((frameNum,1))\n",
    "    for i in range(frameNum):\n",
    "        curFrame = samples[np.arange(i*step,min(i*step+frameSize,wlen))]\n",
    "        #To avoid DC bias, usually we need to perform mean substraction on each frame\n",
    "        curFrame = curFrame - np.mean(curFrame) #Zero-Justified\n",
    "        zcr[i] = sum(curFrame[0:-1]*curFrame[1::]<=0)\n",
    "    return zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1103117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_centroid(x, samplerate=44100):\n",
    "    magnitudes = np.abs(np.fft.rfft(x)) # magnitudes of positive frequencies\n",
    "    length = len(x)\n",
    "    freqs = np.abs(np.fft.fftfreq(length, 1.0/samplerate)[:length//2+1]) # positive frequencies\n",
    "    return np.sum(magnitudes*freqs) / np.sum(magnitudes) # return weighted mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3d565b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Words\n",
    "words = [\"chata\",\"chapa\",\"chave\",\"lata\",\"lapa\",\"lava\",\"casa\",\"capa\",\"cave\",\"cata\",\"chuta\",\"chupa\",\"chuva\",\"farta\",\"farpa\",\"farda\",\"ripa\",\"rita\",\"rica\"]\n",
    "\n",
    "#List of Dataset versions\n",
    "#d = {\"one\": 1, \"two\": 2, \"three\": 3, \"Four\": 4, \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10}\n",
    "\n",
    "d = {\"one\": 1, \"two\": 2, \"three\": 3, \"Four\": 4, \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8,\n",
    "     \"nine\": 9, \"ten\": 10,  \"eleven\": 11, \"twelve\": 12, \"thirteen\": 13, \"fourteen\": 14, \"fifteen\": 15,\n",
    "     \"sixteen\": 16, \"seventeen\": 17, \"eighteen\": 18, \"nineteen\": 19, \"twenty\": 20}\n",
    "\n",
    "iterable = d.keys()\n",
    "\n",
    "#List of people\n",
    "p = ['A','J','N']\n",
    "\n",
    "#List of Phonemes \n",
    "phoneme = [\"_0\", \"_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a9fb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segments = []\n",
    "errors = 0\n",
    "\n",
    "# Workbook is created\n",
    "wb = Workbook()\n",
    "\n",
    "# add_sheet is used to create sheet.\n",
    "sheet1 = wb.add_sheet('Word Analysis')\n",
    "\n",
    "sheet1.write(1, 1, 'Max PW_spec')\n",
    "sheet1.write(2, 1, 'Ceps')\n",
    "sheet1.write(3, 1, 'Avg ZCR')\n",
    "sheet1.write(4, 1, 'Spec_zen')\n",
    "\n",
    "w = 0\n",
    "h = 1\n",
    "\n",
    "for y in words:\n",
    "    for item in iterable:\n",
    "        for x in p:\n",
    "            for t in phoneme:\n",
    "                \n",
    "                if (w == 9):\n",
    "                    w = 0\n",
    "                h += 1\n",
    "                # Write file path\n",
    "                l = str(d[item])\n",
    "                os.chdir(r'C:\\Users\\Dasil\\1. Processamento Digital do Sinal\\Project')\n",
    "                \n",
    "                #MFCC Analysis\n",
    "                filename = 'audio/WD_data/'+x+'_'+y+'_0'+l+t+'.wav' #for Test DataSet\n",
    "                signal, fs = librosa.load(filename)\n",
    "                \n",
    "                sr = fs\n",
    "                \n",
    "                #signal.shape\n",
    "                mfccs = librosa.feature.mfcc(signal, sr=fs, n_mfcc=40, n_fft = 1024, hop_length = 50, n_mels = 130,  fmin = 10, fmax = 4000)         \n",
    "                #mfccs = librosa.feature.mfcc(signal, sr=fs, n_mfcc=40, n_fft = 1024, hop_length = 200, n_mels = 1000,  fmin = 10, fmax = 4000)         \n",
    "\n",
    "                #Normalyse Y scale\n",
    "                mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "\n",
    "                #Visualie MFCC \n",
    "                plt.figure(figsize=(14,4))\n",
    "                #librosa.display.specshow(mfccs[1:][10:],x_axis='time',sr=sr)\n",
    "                librosa.display.specshow(mfccs[25:][:],x_axis='time',sr=sr)\n",
    "                plt.colorbar(format=\"%+2f\")\n",
    "                #plt.plot()\n",
    "                #plt.savefig('Word Detection/MFCCS_ID/'+x+y+l+t+'.jpeg')\n",
    "                \n",
    "                #Calculate Cepstrung and Power Spectrum\n",
    "                ceps, spec = real_cepstrum(signal, n=None)\n",
    "                N = signal.shape[0]\n",
    "\n",
    "                #Power Specturm\n",
    "                power_spec = np.abs(spec[:N//2])**2\n",
    "                #plt.plot(power_spec[0:1500])\n",
    "                index = np.where(power_spec == np.max(power_spec))\n",
    "                print(f'Power_spec: {index[0][0]}')\n",
    "                mfccs.append(index[0][0])\n",
    "\n",
    "                #Calculate Zero Cross Rate\n",
    "                frameSize = 256\n",
    "                overlap = 0\n",
    "                zcr = ZCR(signal, frameSize, overlap)\n",
    "                print(f'Zero Cross Rate: {np.max(zcr)}')\n",
    "                mfccs.append(np.max(zcr))\n",
    "\n",
    "                #Calculate Cepstrum\n",
    "                abs_ceps = np.abs(ceps[:N//2])**2\n",
    "                #plt.plot(abs_ceps[:10])\n",
    "                print(f'Cepstrum: {round(np.max(abs_ceps))}')\n",
    "                \n",
    "                #Spectral Centroid\n",
    "                spec_cen = spectral_centroid(signal, fs)\n",
    "                print(f'Spectral Centroid: {round(spec_cen)}')\n",
    "                \n",
    "                w +=1\n",
    "                sheet1.write(w, h, int(index[0][0]))\n",
    "                w +=1\n",
    "                sheet1.write(w, h, round(np.max(abs_ceps)))\n",
    "                w +=1 \n",
    "                sheet1.write(w, h, round(np.average(zcr)))\n",
    "                w +=1\n",
    "                sheet1.write(w, h, round(spec_cen))  \n",
    "                \n",
    "                \n",
    "                #Clean the graphics\n",
    "                plt.close()\n",
    "                plt.cla()\n",
    "                plt.clf()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff477729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in words:\n",
    "    for item in iterable:\n",
    "        for x in p:\n",
    "                # Write file path\n",
    "                if(d[item] <10):\n",
    "                    k = '0'\n",
    "                elif(d[item] == 10):\n",
    "                    k=''\n",
    "                elif(d[item] == 20):\n",
    "                    k=''\n",
    "                else:\n",
    "                    k = '0' \n",
    "                l = str(d[item])\n",
    "                os.chdir(r'C:\\Users\\Dasil\\1. Processamento Digital do Sinal\\Project')\n",
    "                \n",
    "                #MFCC Analysis\n",
    "                filename = 'audio/PD_data/'+x+'_'+y+'_'+k+l+'_1.wav' #for Test DataSet\n",
    "                \n",
    "                l = d[item]\n",
    "                \n",
    "                # Read file path\n",
    "                fs, audio1 = read(filename)\n",
    "                \n",
    "                # Fix-sized segmentation (breaks a signal into non-overlapping segments)\n",
    "                signal = audio1 / (2**15)\n",
    "                signal_len = len(signal)\n",
    "                segment_size_t = 1 # segment size in seconds\n",
    "                segment_size = segment_size_t * fs  # segment size in samples\n",
    "\n",
    "                # Break signal into list of segments in a single-line Python code\n",
    "                segment1 = audio1\n",
    "                segments = [segment1]\n",
    "                \n",
    "                #l += 10\n",
    "                \n",
    "                l = str(l)\n",
    "                \n",
    "                if(d[item] <10):\n",
    "                    k = '0'\n",
    "                elif(d[item] > 10):\n",
    "                    k=''\n",
    "                \n",
    "                for iS, s in enumerate(segments):\n",
    "                        write('audio/PD_data2/'+x+'_'+y+'_'+k+l+'_1.wav'.format(segment_size_t * iS, segment_size_t * (iS + 1)), fs, (s))\n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
