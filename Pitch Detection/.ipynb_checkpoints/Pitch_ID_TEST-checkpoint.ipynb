{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f740b57",
   "metadata": {},
   "source": [
    "# **IF YOU GET THROUGH ME YOU'RE THE ONE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fde7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import pyAudioAnalysis\n",
    "import pydub\n",
    "import ffmpeg\n",
    "\n",
    "from numpy import sin, cos, pi, linspace, arange, log10, absolute\n",
    "from numpy.random import randn\n",
    "from scipy.signal import lfilter, lfilter_zi, filtfilt, butter, freqz, welch\n",
    "from scipy.io.wavfile import read , write\n",
    "from scipy.signal import spectrogram\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import ylabel, xlabel\n",
    "from matplotlib.pyplot import plot, legend, show, grid, figure, savefig#, hold\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65945727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def real_cepstrum(x, n=None):\n",
    "# Compute the real cepstrum of a real sequence\n",
    "#    x : ndarray\n",
    "#        Real sequence to compute real cepstrum of.\n",
    "#    n : {None, int}, optional\n",
    "#        Length of the Fourier transform.\n",
    "#    Returns\n",
    "#    -------\n",
    "#    ceps: ndarray\n",
    "#        The real cepstrum.\n",
    "\n",
    "    spectrum = np.abs(np.fft.fft(x, n=n))**2\n",
    "    ceps = np.fft.ifft(np.log(spectrum))\n",
    "\n",
    "    return ceps, spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero Crossing Rate\n",
    "\n",
    "def ZCR(samples, frameSize, overlap):\n",
    "    wlen = len(samples)\n",
    "    step = frameSize - overlap\n",
    "    frameNum = math.ceil(wlen/step)\n",
    "    zcr = np.zeros((frameNum,1))\n",
    "    for i in range(frameNum):\n",
    "        curFrame = samples[np.arange(i*step,min(i*step+frameSize,wlen))]\n",
    "        #To avoid DC bias, usually we need to perform mean substraction on each frame\n",
    "        curFrame = curFrame - np.mean(curFrame) #Zero-Justified\n",
    "        zcr[i] = sum(curFrame[0:-1]*curFrame[1::]<=0)\n",
    "    return zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfeb223",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'audio/training/N_rec3.wav'\n",
    "\n",
    "#List of Words\n",
    "words = [\"_chata_0\",\"_chapa_0\",\"_chave_0\",\"_lata_0\",\"_lapa_0\",\"_lava_0\",\"_casa_0\",\"_capa_0\",\"_cave_0\",\"_cata_0\",\"_chuta_0\",\"_chupa_0\",\"_chuva_0\",\"_farta_0\",\"_farpa_0\",\"_farda_0\",\"_ripa_0\",\"_rita_0\",\"_rica_0\"]\n",
    "\n",
    "#List of Dataset versions\n",
    "d = {\"one\": 1, \"two\": 2}\n",
    "iterable = d.keys()\n",
    "\n",
    "#List of people\n",
    "p = ['A','J','N']\n",
    "\n",
    "TypeTest = True #ALL DATA ANALYSIS OR FILENEMAE ONLY\n",
    "\n",
    "fs, audio1 = read(filename)\n",
    "f,t,S1 = spectrogram(audio1, fs, window='flattop', nperseg=fs//10, noverlap=fs//20, scaling='spectrum', mode='magnitude')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e60c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters of Identification \n",
    "\n",
    "Pitch = [[350, 405],[406,500]] #A/(J&N)\n",
    "Zcr_Avg = [[19,40],[12,18]] #(J/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c63c7e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dasil\\AppData\\Local\\Temp/ipykernel_9436/785430498.py:26: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, audio1 = read(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cepstrum 361\n",
      "IS PIKACHU!!\n"
     ]
    }
   ],
   "source": [
    "# add_sheet is used to create sheet.\n",
    "sheet1 = wb.add_sheet('Pitch Analysis')\n",
    "\n",
    "#Write Data for the table\n",
    "sheet1.write(1, 0, 'Andre')\n",
    "sheet1.write(4, 0, 'Joaquin')\n",
    "sheet1.write(7, 0, 'Nuno')\n",
    "sheet1.write(0, 1, 'TRUE')\n",
    "sheet1.write(0, 2, 'FALSE')\n",
    "\n",
    "h = 2\n",
    "\n",
    "h=1\n",
    "w=0\n",
    "flag = False\n",
    "\n",
    "if (TypeTest):\n",
    "    for y in words:\n",
    "        for item in iterable:\n",
    "            h += 1\n",
    "            if (w == 9):\n",
    "                w = 0        \n",
    "            for x in p:\n",
    "                Check = x #For Validation\n",
    "                \n",
    "                #Write file path\n",
    "                l = str(d[item])\n",
    "                \n",
    "                filename = 'audio/training/'+x+y+l+'.wav'\n",
    "\n",
    "                #Read file path\n",
    "                fs, audio1 = read(filename)\n",
    "                f,t,S1 = spectrogram(audio1, fs, window='flattop', nperseg=fs//10, noverlap=fs//20, scaling='spectrum', mode='magnitude')\n",
    "\n",
    "                #Apply butterworth Filter\n",
    "                wn = 1500/(fs/2)\n",
    "                b3,a3 = butter(4, wn)\n",
    "                audio1_filt = lfilter(b3,a3,audio1)\n",
    "\n",
    "                #Analyze Audio (With audio Segment)\n",
    "                song = AudioSegment.from_wav(filename)\n",
    "\n",
    "                #Divide Audio in two\n",
    "                db = -30\n",
    "                segments = split_on_silence(song, min_silence_len = 100, silence_thresh = db)\n",
    "                while len(segments) != 2:\n",
    "                    db = db-1\n",
    "                    segments = split_on_silence(song, min_silence_len = 100, silence_thresh = db)\n",
    "                    if db < -90:\n",
    "                        break\n",
    "\n",
    "                #Find out the number of Segments\n",
    "                n = len(segments)\n",
    "                #print(\"Size of List\", n)\n",
    "\n",
    "                samples = segments[0].get_array_of_samples()\n",
    "                samples = np.array(samples)\n",
    "\n",
    "                # Calculate Power Spectrum & Cepstrum\n",
    "                ceps, spec = real_cepstrum(samples, n=None)\n",
    "                N = samples.shape[0]\n",
    "\n",
    "                # Power Specturm\n",
    "                power_spec = np.abs(spec[:N//2])**2\n",
    "\n",
    "                # Calculate Zero Cross Rate\n",
    "                frameSize = 256\n",
    "                overlap = 0\n",
    "                zcr = ZCR(samples, frameSize, overlap)\n",
    "\n",
    "                index = np.where(power_spec == np.max(power_spec))\n",
    "\n",
    "                abs_ceps = np.abs(ceps[:N//2])**2\n",
    "                np.max(abs_ceps)\n",
    "\n",
    "                if (Jceps[0] < ceps < Jceps[1]):\n",
    "                    print('IS JOAQUIN!!!')\n",
    "                elif (Aceps[0] < ceps < Aceps[1]):\n",
    "                    print('IS ANDRE!!')\n",
    "                else:\n",
    "                    print('IS PIKACHU!!')\n",
    "                \n",
    "\n",
    "                w +=1\n",
    "                sheet1.write(w, h, int(index[0][0]))\n",
    "                w +=1\n",
    "                sheet1.write(w, h, round(np.max(abs_ceps)))\n",
    "                w +=1 \n",
    "                sheet1.write(w, h, round(np.average(zcr)))\n",
    "                flag = True\n",
    "\n",
    "else:\n",
    "    fs, audio1 = read(filename)\n",
    "    check(filename[15])\n",
    "    f,t,S1 = spectrogram(audio1, fs, window='flattop', nperseg=fs//10, noverlap=fs//20, scaling='spectrum', mode='magnitude')\n",
    "    \n",
    "    if (Jceps[0] < ceps < Jceps[1]):\n",
    "    print('IS JOAQUIN!!!')\n",
    "    elif (Aceps[0] < ceps < Aceps[1]):\n",
    "        print('IS ANDRE!!')\n",
    "    else:\n",
    "        print('IS PIKACHU!!')\n",
    "    \n",
    "    \n",
    "wb.save('audio/DataResults.xls')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
