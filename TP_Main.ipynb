{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d361b95c",
   "metadata": {},
   "source": [
    "# Trabalho Prático Processamento Digital do Sinal\n",
    "\n",
    "Desenvolvimento de um algoritmo de análise de voz de um aluno enquanto este diz a\n",
    "palavra-passe de acesso/registo na sala de aula. Este algoritmo tem 2 objetivos:\n",
    "\n",
    "(1) identificar o aluno que diz a palavra-passe.\n",
    "(2) identificar a palavra-passe dita pelo aluno (ver componente(b) do diagrama)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611690af",
   "metadata": {},
   "source": [
    "-> Voice Verification or Voice Recognition? \n",
    "\n",
    "Voice verification systems are different from voice recognition systems although the two are often confused. Voice recognition is used to translate the spoken word into a specific response, while voice verification verifies the vocal characteristics against those associated with the enrolled user.\n",
    "\n",
    "-> Pitch\n",
    "    In singing, we are familiar with the range from Soprano: the highest female voice, down through Mezzo-Soprano, Contralto, Tenor and Baritone – on to Bass, the lowest deep male voice. The definitions aren't as well known with the spoken word, but the range is similar. \n",
    "    \n",
    "    \n",
    "-> Tone\n",
    "    Everyone has a tone of voice—a pattern of speaking—as individual as their fingerprint.\n",
    "\n",
    "    \n",
    "-> Intonation\n",
    "    Words in sentences rise and fall. How should the script be read to portray the meaning best – and not mislead? \n",
    "\n",
    "-> Speech\n",
    "    Speech signal processing is a diverse field that relies on knowledge of language at the levels of Signal processing.\n",
    "    \n",
    "        1.) Acoustics (P¥).\n",
    "        2.) Phonetics ( ^ ^ ^ ) Language-independent.\n",
    "        3.) Phonology ( ^ ^ ).\n",
    "        4.) Morphology ( i ^ ^ ^ ).\n",
    "        5.) Syntax ( ^ , £ ) Language-dependent.\n",
    "        6.) Semantics (\\%X¥).\n",
    "        7.) Pragmatics ( i f , f f l ^ ).\n",
    "        8.) Contains significant energy from zero frequency up to around 5 kHz.\n",
    "        \n",
    "    - Most of energy between 20 Hz to about 7KHz.\n",
    "    - Human ear sensitive to energy between 50 Hz and 4KHz.\n",
    "\n",
    "-> Speaker Recnognition Systems\n",
    "    contain two main Modules\n",
    "    \n",
    "    -> Feature extraction\n",
    "        Extract a small amount of data from voice signal that can be used to represent each speaker.\n",
    "        \n",
    "    -> Feature Matching\n",
    "        Procedure to identify the unknow speaker by comparing extracted features from his/her voice input with the ones from a set of known speakers. \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74292bd2",
   "metadata": {},
   "source": [
    "# Choice of Methodology\n",
    "\n",
    "-> Linear Predictive Coding (LPC).\n",
    "\n",
    "-> Mel-Frequency Cepstrum Coefficients (MFCC).\n",
    "\n",
    "-> Perceptual Linear Predictive Analysis (PLP).\n",
    "\n",
    "Options: \n",
    "Adaptative Predictive Coding (APC).\n",
    "Sub-band Coding (SBC).\n",
    "Linear Predictive Coding (LPC).\n",
    "Multipulse Excited Linear Predictive Coding (MLPC).\n",
    "Code Excited Linear Prediction (CELP).\n",
    "Vector Sum Excited Linear Prediction (VSELP).b\n",
    "\n",
    "The Purspose of the MFCC processor is to mimic human ears. (Sampling rate above 10000Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Install Libraryes\n",
    "\n",
    "#!pip install librosa\n",
    "#!pip install IPython\n",
    "#!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfafeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from numpy import sin, cos, pi, linspace, arange, log10, absolute\n",
    "from numpy.random import randn\n",
    "from scipy.signal import lfilter, lfilter_zi, filtfilt, butter, freqz, welch\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.signal import spectrogram\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import ylabel, xlabel\n",
    "from matplotlib.pyplot import plot, legend, show, grid, figure, savefig#, hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e576ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'casa1.wav'\n",
    "fs, audio1 = read(filename)\n",
    "f,t,S1 = spectrogram(audio1, fs, window='flattop', nperseg=fs//10, noverlap=fs//20, scaling='spectrum', mode='magnitude')\n",
    "print('filename: ', filename)\n",
    "print('Data Length (s): ',t[-1])\n",
    "print('Sampling frequency (samples/s): ', fs)\n",
    "\n",
    "#Load the Audio with Librosa\n",
    "x, sr = librosa.load('casa1.wav')\n",
    "print(\"\\nLibrosa Audio\")\n",
    "print(x.shape)\n",
    "print(sr)\n",
    "\n",
    "#Librosa (Wave Visualization)\n",
    "pyplot.figure(figsize=(14,5))\n",
    "librosa.display.waveplot(x,sr=sr)\n",
    "\n",
    "#Playing Audio (Reproduce Audio)\n",
    "ipd.Audio('casa1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4118dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Spectrograms\n",
    "\n",
    "#Display a spectrogramusing libosa.display specshow (String Title Limited)\n",
    "#X = librosa.stft(x)\n",
    "#Xdb = librosa.amplitude_to_db(abs(X))\n",
    "#pyplot.figure(figsize=(14,5))\n",
    "#librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "\n",
    "#Spectrogram \n",
    "pyplot.rcParams['figure.figsize'] = 14,5\n",
    "pyplot.pcolormesh(t, f[:450], S1[:450][:])\n",
    "pyplot.title(\"Spectrogram\")\n",
    "xlabel('time(s)')\n",
    "ylabel('frequency(Hz)')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = 1500/(fs/2)\n",
    "b3,a3 = butter(4, wn)\n",
    "audio1_filt = lfilter(b3,a3,audio1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.rcParams['figure.figsize'] = 16,5\n",
    "#plot(audio1,'r')\n",
    "plot(absolute(audio1_filt),'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cb603",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [True if item > 0.3*1e8 else False for item in audio1_filt**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b71d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431308c",
   "metadata": {},
   "source": [
    "# Speech Recognition \n",
    "\n",
    "Just a simple test for references.\n",
    "\n",
    "https://nickmccullum.com/python-speech-recognition/\n",
    "\n",
    "(Works better for english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbcb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "myaudio = sr.AudioFile('casa1.wav')\n",
    "\n",
    "with myaudio as source:\n",
    "\n",
    "    audio = r.record(source)\n",
    "    \n",
    "type(audio)\n",
    "\n",
    "#Speech_recognition.AudioData\n",
    "\n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145b285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
